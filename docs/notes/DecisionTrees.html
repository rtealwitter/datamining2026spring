<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Decision Trees and Boosting</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../eve.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c5a5d5e27fcc88644031c24cff017230.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="shortcut icon" href="../eve.ico">
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GZHXTPTRRE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GZHXTPTRRE');
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Spring 2026</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://discord.gg/dES3fSPEeC"> 
<span class="menu-text">Discord</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.gradescope.com/courses/1091652"> 
<span class="menu-text">Gradescope</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.rtealwitter.com/datamining2025/"> 
<span class="menu-text">Fall 2025</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link active" data-scroll-target="#decision-trees">Decision Trees</a></li>
  <li><a href="#adaptive-boosting-adaboost" id="toc-adaptive-boosting-adaboost" class="nav-link" data-scroll-target="#adaptive-boosting-adaboost">Adaptive Boosting (AdaBoost)</a></li>
  <li><a href="#gradient-boosting" id="toc-gradient-boosting" class="nav-link" data-scroll-target="#gradient-boosting">Gradient Boosting</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>Decision Trees and Boosting</strong></h1>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<p>Feature transformations and neural networks are powerful tools for supervised learning, but they can be difficult to interpret. Today, we’ll consider a more intuitive model class called trees, which, until very recently, gave the best performance on many supervised learning tasks.</p>
<section id="decision-trees" class="level3">
<h3 class="anchored" data-anchor-id="decision-trees">Decision Trees</h3>
<p>Decision trees are a simple yet powerful model class that can be used for both classification and regression tasks. For simplicity, we’ll define them in terms of classification, but the same ideas apply to regression.</p>
<p>Decision trees work by recursively partitioning the feature space into regions that are as homogeneous as possible with respect to the target variable.</p>
<center>
<img src="images/tree_example.svg" class="responsive-img">
</center>
<p>The tree structure is incredibly intuitive, and likely the most natural way to represent a decision-making process. At each internal node, the tree splits the data based on a feature and a threshold. The goal is to find the split that <em>best</em> (more on this later) separates the classes.</p>
<p>Like gradient descent, decision trees use a <em>greedy</em> approach to learning. As we build the tree, we recursively evaluate the data at each leaf, choosing the feature and threshold that best separates the classes. Let <span class="math inline">\(\ell\)</span> be a leaf <em>after</em> the split at the <em>prior</em> leaf, and <span class="math inline">\(p^{(\ell)}_c\)</span> be the proportion of points in leaf <span class="math inline">\(\ell\)</span> that are of class <span class="math inline">\(c\)</span>. Without loss of generality, suppose that <span class="math inline">\(c=0\)</span> is the majority class. (Soon, we’ll consider weighted points, in which case we will define the weighted majority.) If we reach leaf <span class="math inline">\(\ell\)</span>, we predict that the point belongs to the majority class.</p>
<p>The question is what split minimizes the loss of the resulting predictions. In particular, we’d like to minimize the <em>expected</em> loss of the predictions where the expectation is taken over the proportion of points that make it to the leaf <span class="math inline">\(p^{(\ell)}\)</span>: <span class="math display">\[
\mathbb{E}_\ell[\mathcal{L}(\ell)] = \sum_\ell \mathcal{L}(\ell) \cdot p^{(\ell)}.
\]</span> There are several ways to define the loss of a leaf, but several common ones are:</p>
<p><strong>Error Rate</strong>: The error rate is the proportion of points in the leaf that are not of the predicted majority class. That is, <span class="math display">\[
\mathcal{L}_\text{error}(\ell) = 1 - p^{(\ell)}_0.
\]</span></p>
<p><strong>Gini Impurity</strong>: The Gini impurity measures the probability of misclassifying a randomly chosen point from the leaf <em>if we were to randomly assign it to a class according to the class proportions</em>. That is, <span class="math display">\[
\mathcal{L}_\text{Gini}(\ell) = \sum_{c} p^{(\ell)}_c (1 - p^{(\ell)}_c).
\]</span> With a little algebra, we can rewrite this as: <span class="math display">\[
\mathcal{L}_\text{Gini}(\ell) = \sum_{c} p^{(\ell)}_c - \left(p^{(\ell)}_c\right)^2 = 1 - \sum_{c} \left(p^{(\ell)}_c\right)^2.
\]</span></p>
<p><strong>Information Gain</strong>: Like logistic regression, information gain uses the entropy of the leaf to measure the error. That is, <span class="math display">\[
\mathcal{L}_\text{InfoGain}(\ell) = H(\ell) = -\sum_{c} p^{(\ell)}_c \log(p^{(\ell)}_c).
\]</span> Since the entropy is a measure of uncertainty, we call the reduction in entropy from the prior leaf to the resulting leaves after the split the <em>information gain</em>.</p>
<p>Previously, we updated the parameters of our model to minimize the loss of our predictions. In decision trees, we search over all possible splits of the data to find the one that minimizes the expected loss. While this sounds expensive, in practice, there are a limited number of feasible splits.</p>
<p>We’ve discussed decision trees in terms of classification, but they can also be used for regression tasks. What prediction would a leaf make in a regression task? How could we measure the loss of this prediction?</p>
<p>On their own, decision trees are not particularly expressive. But, they can be <em>boosted</em> to create remarkably powerful models. A boosted model is a collection of weaker learners that together make the final prediction.</p>
</section>
<section id="adaptive-boosting-adaboost" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-boosting-adaboost">Adaptive Boosting (AdaBoost)</h3>
<p>In adaptive boosting, we iteratively train a model to improve the composite model we’ve built so far. For simplicity, we’ll explore adaptive boosting in the context of binary classification, but the method can be generalized to regression tasks.</p>
<p>Let <span class="math inline">\(f_t : \mathbb{R}^d \to \{-1, 1\}\)</span> be the model learned at iteration <span class="math inline">\(t\)</span>. The combined prediction is given by an ensemble model <span class="math inline">\(F_t : \mathbb{R}^d \to \mathbb{R}\)</span>. The ensemble model is defined as a weighted sum of the predictions of the individual models: <span class="math display">\[
F_t(x) = \alpha_1 f_1(x) + \alpha_2 f_2(x) + \ldots + \alpha_t f_t(x)
= F_{t-1}(x) + \alpha_t f_t(x),
\]</span> where <span class="math inline">\(\alpha_k &gt; 0\)</span> is a weight that determines the importance of the model <span class="math inline">\(f_k\)</span> in the ensemble.</p>
<p>Given <span class="math inline">\(F_{t-1}\)</span>, we are interested in learning a new model <span class="math inline">\(f_t\)</span> and a new weight <span class="math inline">\(\alpha_t\)</span> that minimizes the loss of the composite model. We’ll define the loss as <span class="math display">\[
\mathcal{L}(F_t) = \sum_{i=1}^n e^{-y^{(i)} F_t(\mathbf{x}^{(i)})},
\]</span> where <span class="math inline">\(y^{(i)} \in \{-1, 1\}\)</span> is the true label of the <span class="math inline">\(i\)</span>-th training example. When the composite model output is the same sign as the true label, the term in the exponent is negative, and the contribution to the error is less than 1. When the composite model output is the opposite sign as the true label, the term in the exponent is positive, and the contribution to the loss is (potentially much) greater than 1.</p>
<p>Using the multiplication property of exponents, and the definition of <span class="math inline">\(F_t\)</span>, we can rewrite the loss as <span class="math display">\[
\mathcal{L}(F_t) = \sum_{i=1}^n e^{-y^{(i)} (F_{t-1}(\mathbf{x}^{(i)}) + \alpha_t f_t(\mathbf{x}^{(i)}))}
= \sum_{i=1}^n e^{-y^{(i)} F_{t-1}(\mathbf{x}^{(i)})} e^{-y^{(i)} \alpha_t f_t(\mathbf{x}^{(i)})}.
\]</span> Let <span class="math inline">\(w^{(i)}_{t-1} = e^{-y^{(i)} F_{t-1}(\mathbf{x}^{(i)})}\)</span> be the weight of the <span class="math inline">\(i\)</span>th training example at iteration <span class="math inline">\(t\)</span>. Notice that these weights are independent of the new model <span class="math inline">\(f_t\)</span> and the new weight <span class="math inline">\(\alpha_t\)</span>. Then, partitioning the summation, we can write the error as <span class="math display">\[
\begin{align}
\mathcal{L}(F_t) &amp;=
\sum_{i: y^{(i)} = f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1} e^{-\alpha_t} + \sum_{i: y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1} e^{\alpha_t}
\\&amp;= \sum_{i=1}^n w^{(i)}_{t-1} e^{-\alpha_t} + \sum_{i: y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1} (e^{\alpha_t} - e^{-\alpha_t})
\\&amp;= \sum_{i=1}^n w^{(i)}_{t-1} e^{-\alpha_t} + (e^{\alpha_t} - e^{-\alpha_t}) \sum_{i: y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1}.
\end{align}
\]</span></p>
<p>With <span class="math inline">\(F_{t-1}\)</span> fixed, minimizing <span class="math inline">\(\mathcal{L}(F_t)\)</span> is equivalent to minimizing the weighted error of the new model <span class="math inline">\(f_t\)</span> i.e., the sum of the weights for all misclassified points. Once we learn a decision tree <span class="math inline">\(f_t\)</span> that minimizes the weighted error, we can find the optimal weight <span class="math inline">\(\alpha_t\)</span> by differentiating the loss with respect to <span class="math inline">\(\alpha_t\)</span> and setting it to zero. In particular, we have <span class="math display">\[
\frac{\partial \mathcal{L}(F_t)}{\partial \alpha_t}
= \sum_{i : y^{(i)} = f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1} (-e^{-\alpha_t})
+ \sum_{i : y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1} e^{\alpha_t}
= 0
\]</span> which tells us that <span class="math display">\[
e^{-\alpha_t} \sum_{i : y^{(i)} = f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1}
= e^{\alpha_t} \sum_{i : y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1}.
\]</span> Taking the logarithm of both sides, we have: <span class="math display">\[
-\alpha_t + \log\left(\sum_{i : y^{(i)} = f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1}\right)
= \alpha_t + \log\left(\sum_{i : y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1}\right).
\]</span> Rearranging, we have <span class="math display">\[
\alpha_t = \frac{1}{2} \log\left(\frac{1-\epsilon_t}{\epsilon_t}\right)
\]</span> where <span class="math inline">\(\epsilon_t = \frac{\sum_{i : y^{(i)} \neq f_t(\mathbf{x}^{(i)})} w^{(i)}_{t-1}}{\sum_{i=1}^n w^{(i)}_{t-1}}\)</span> is the weighted error rate of the model <span class="math inline">\(f_t\)</span>.</p>
<p>At each iteration <span class="math inline">\(t\)</span>, we compute the weights <span class="math inline">\(w^{(i)}_{t-1}\)</span> based on which points the current ensemble model <span class="math inline">\(F_{t-1}\)</span> are misclassifying. We then learn a new model <span class="math inline">\(f_t\)</span> that minimizes the weighted error, adapting to correct the mistakes of the current ensemble. Finally, we compute the optimal weight <span class="math inline">\(\alpha_t\)</span> for the new model based on its weighted error rate.</p>
<center>
<img src="images/tree_adaboost_learning.svg" class="responsive-img">
</center>
<p>The final prediction algorithm combines each of the weak learners.</p>
<center>
<img src="images/tree_adaboost_predicting.svg" class="responsive-img">
</center>
<p>The AdaBoost algorithm is agnostic to the choice of weak learner, but decision trees are efficient and interpretable: Each weak learner can be trained quickly, and the resulting decision tree can be understood as a weighted vote of the individual trees.</p>
</section>
<section id="gradient-boosting" class="level3">
<h3 class="anchored" data-anchor-id="gradient-boosting">Gradient Boosting</h3>
<p>Remarkably, AdaBoost can be viewed as gradient descent where the loss function is defined over the <em>predictions</em> on points rather than the <em>parameters</em> of the model.</p>
<p>Let <span class="math inline">\(\mathcal{L}\)</span> be a differentiable loss function defined over the predictions of the model on the training data. In AdaBoost, we used the exponential loss, but we could use other loss functions like squared error or logistic loss. Rather than considering weak learners that are binary classifiers, we will now consider real-valued functions <span class="math inline">\(f_t : \mathbb{R}^d \to \mathbb{R}\)</span>.</p>
<p>As before, the combined prediction is given by an ensemble model <span class="math inline">\(F_t : \mathbb{R}^d \to \mathbb{R}\)</span>. The ensemble model is defined as a weighted sum of the predictions of the individual models: <span class="math display">\[
F_t(x) = \alpha_1 f_1(x) + \alpha_2 f_2(x) + \ldots + \alpha_t f_t(x) = F_{t-1}(x) + \alpha_t f_t(x).
\]</span></p>
<p>Our goal is to find a weak learner <span class="math inline">\(f_t\)</span> that minimizes the loss <span class="math display">\[
\arg \min_{f_t} \sum_{i=1}^n \mathcal{L}(y^{(i)}, F_{t-1}(\mathbf{x}^{(i)}) + f_t(\mathbf{x}^{(i)})).
\]</span> Recall that the gradient descent update subtracts the gradient of the parameter (opposite the direction of steepest ascent) for a small learning rate <span class="math inline">\(\alpha\)</span>. Instead of updating the parameters of the model, we will update the predictions of the model. In our boosting language, the gradient descent update for the <span class="math inline">\(i\)</span>th prediction is <span class="math display">\[
F_t(\mathbf{x}^{(i)}) = F_{t-1}(\mathbf{x}^{(i)}) - \alpha \frac{ \partial \mathcal{L}(y^{(i)}, F_{t-1}(\mathbf{x}^{(i)}))}{\partial F_{t-1}(\mathbf{x}^{(i)})}.
\]</span> In practice, finding a function that exactly matches the gradient is difficult, so we will instead find a function that <em>approximates</em> the gradient. That is, we train a weak learner <span class="math inline">\(f_t\)</span> to fit the points <span class="math inline">\((\mathbf{x}^{(i)}, \frac{ \partial \mathcal{L}(y^{(i)}, F_{t-1}(\mathbf{x}^{(i)}))}{\partial F_{t-1}(\mathbf{x}^{(i)})})\)</span> for <span class="math inline">\(i \in \{1, \ldots n\}\)</span>. When the loss is the squared error loss, i.e., <span class="math display">\[
\mathcal{L}(y, F_{t-1}(\mathbf{x})) = \frac12 (F_{t-1}(\mathbf{x}) - y)^2,
\]</span> the gradient of the loss with respect to the prediction is simply the residual between the prior prediction and the label, i.e., <span class="math display">\[
\frac{ \partial \mathcal{L}(y, F_{t-1}(\mathbf{x}))}{\partial F_{t-1}(\mathbf{x})} = F_{t-1}(\mathbf{x}) - y.
\]</span> In this, gradient boosting has a nice interpretation as an iterative process of fitting a model to the residuals of the prior model. Once we have trained the weak learner <span class="math inline">\(f_t\)</span>, we can select the weight <span class="math inline">\(\alpha_t\)</span> to minimize the loss of the composite model: <span class="math display">\[
\alpha_t = \arg \min_\alpha \sum_{i=1}^n \mathcal{L}(y^{(i)}, F_{t-1}(\mathbf{x}^{(i)}) + \alpha f_t(\mathbf{x}^{(i)})).
\]</span> When the loss is differentiable and convex (e.g., mean squared error), we can find the optimal weight <span class="math inline">\(\alpha_t\)</span> by differentiating the loss with respect to <span class="math inline">\(\alpha_t\)</span> and setting it to zero.</p>
<p>The gradient boosting algorithm called <a href="https://en.wikipedia.org/wiki/XGBoost">XGBoost</a> is a popular implementation. Since 2014, XGboost has basically been the best performing model on many supervised learning tasks. However, foundation models like <a href="https://en.wikipedia.org/wiki/TabPFN">TabPFN</a> are starting to outperform XGBoost on small to medium-sized datasets. Like modern models, TabPFN uses a transformer architecture, and is trained on some 130 million synthetic datasets. While XGBoost requires relearning an ensemble for each new dataset, TabPFN can be run without any training by simply passing labeled example data, and unlabeled validation data as input to the model.</p>



</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const wordsPerMinute = 200;
  const text = document.body.innerText;
  const words = text.trim().split(/\s+/).length;
  const readingTime = Math.ceil(words / wordsPerMinute);

  const readTimeEl = document.createElement("div");
  readTimeEl.innerText = `⏱️ ${readingTime} min read`;

  // Style it to appear centered
  readTimeEl.style.fontSize = "0.9em";
  readTimeEl.style.margin = "1em auto";
  readTimeEl.style.textAlign = "left";
  readTimeEl.style.width = "100%";

  const title = document.querySelector("h1");
  if (title) {
    title.parentNode.insertBefore(readTimeEl, title.nextSibling);
  }
});
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>